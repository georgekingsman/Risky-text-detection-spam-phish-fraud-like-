\documentclass[11pt]{article}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{xcolor}
\geometry{margin=1in}
\graphicspath{{figs/}}

\title{DedupShift: Credible Cross-Domain Benchmarking for Risky Text Detection}
\author{}
\date{}

\begin{document}
\maketitle

\begin{abstract}
We present a reproducible benchmark for risky text detection (spam/phish/fraud-like) across three domains: SMS, email, and modern chat (Telegram). We report strong in-domain baselines (F1 up to 0.99) but substantial cross-domain degradation (F1 range 0.09--0.56), demonstrating that even neural baselines (DistilBERT F1 0.56) do not eliminate domain shift. We introduce \textbf{DedupShift}, a deduplicated split protocol that removes $\sim$8--15\% near-duplicates before re-splitting to reduce leakage from template-heavy corpora. Our suite includes perturbation-based robustness evaluation, normalization defense ablation, TextAttack sanity checks, and domain-shift diagnostics (JSD) across three domains with varying distributional characteristics. We demonstrate that Evasion-Aware Training (EAT) partially recovers cross-domain and adversarial robustness without significant clean performance loss.
\end{abstract}

\section{Introduction}
Risky text detection---identifying spam, phishing, and fraud-like messages---remains challenging under domain shift and adversarial perturbations. Modern messaging platforms (Telegram, WhatsApp) exhibit different linguistic patterns than legacy SMS and email, creating a ``modern domain gap'' that traditional models struggle to bridge.

\textbf{Our contributions are three-fold:}
\begin{enumerate}
    \item \textbf{Claim A (Protocol):} DedupShift significantly reduces cross-split near-duplicate leakage (from 2--8\% to $<$1\%), changing model rankings and exposing true generalization gaps.
    \item \textbf{Claim B (Evaluation):} Under domain shift + evasion attacks, clean F1 alone is insufficient; our robustness matrix reveals model vulnerabilities invisible in standard evaluation.
    \item \textbf{Claim C (Defense):} EAT/AttackMix improves cross-domain and adversarial robustness without significantly sacrificing clean performance, validated across all three domains.
\end{enumerate}

\section{Datasets and DedupShift Protocol}

\subsection{Dataset Statistics}
We evaluate on three corpora spanning legacy (SMS, email) and modern (chat) domains:
\input{tables/dataset_stats_table.tex}

\subsection{DedupShift Protocol}
DedupShift removes exact and near-duplicates (SimHash with Hamming threshold $h_{\text{thresh}}=3$) \textit{before} train/val/test splitting to prevent template-driven leakage common in spam corpora. This is critical: without deduplication, up to 8\% of test samples have near-exact matches in training data, inflating reported metrics.

\subsection{Domain Shift Analysis}
We quantify distributional shift using Jensen-Shannon Divergence (JSD) on character n-gram distributions:
\input{tables/domain_shift_3domain.tex}

The larger JSD between Telegram and legacy corpora (SMS, SpamAssassin) explains the sharper cross-domain degradation observed in modern domain transfers.

\section{Baselines and Methods}
\textbf{Lightweight baselines:} TF-IDF word/char features with LR/SVM.\\
\textbf{Embedding baseline:} MiniLM (sentence-transformers) + LR.\\
\textbf{Neural anchor:} DistilBERT fine-tuned (max\_len=128, batch=8, 2 epochs).\\
\textbf{Defense methods:} (i) Text normalization; (ii) EAT/AttackMix---training-time augmentation with obfuscation/paraphrase perturbations.

\section{Results}

\subsection{Cross-Domain Generalization (Claim B)}
\input{tables/cross_domain_3domain.tex}

Key observations:
\begin{itemize}
    \item In-domain performance is strong (F1 $>$0.90 for TF-IDF on SMS/SpamAssassin).
    \item Cross-domain degradation is severe, especially transfers involving Telegram (modern domain).
    \item EAT partially recovers cross-domain performance, supporting Claim C.
\end{itemize}

\subsection{DedupShift Impact (Claim A)}
\input{tables/dedup_effect.tex}

DedupShift changes model rankings: models that exploit template memorization (high leakage) show larger performance drops after deduplication.

\subsection{Robustness Under Evasion Attacks (Claims B \& C)}
\input{tables/robustness_summary.tex}

\begin{figure}[t]
\centering
\includegraphics[width=0.95\linewidth]{fig_robustness_delta_dedup.png}
\caption{\textbf{Robustness deltas on deduplicated splits.} EAT shows resilience to obfuscation and paraphrase attacks compared to baseline models. DistilBERT shows high vulnerability to all attacks despite strong clean performance.}
\label{fig:robustness_delta}
\end{figure}

\subsection{Cost-Throughput Trade-off (Green AI)}
\begin{figure}[t]
\centering
\includegraphics[width=0.95\linewidth]{fig_cost_throughput.png}
\caption{\textbf{Robustness vs. inference cost trade-off.} TF-IDF models achieve 10--100$\times$ higher throughput than neural models while maintaining competitive robust F1. MiniLM offers a middle ground. This supports deployment in resource-constrained settings.}
\label{fig:cost_throughput}
\end{figure}

\section{Hyperparameter Sensitivity}
\input{tables/sensitivity_dedup_threshold.tex}

\begin{figure}[t]
\centering
\includegraphics[width=0.95\linewidth]{fig_sensitivity_dedup_threshold.png}
\caption{\textbf{DedupShift threshold sensitivity.} Default $h_{\text{thresh}}=3$ balances deduplication rate and data retention.}
\label{fig:sensitivity}
\end{figure}

\section{Related Work}
\textbf{Spam/phish detection.} Classic statistical filters \cite{guzella2009review,almeida2011sms} and BERT-family models \cite{sanh2019distilbert} are common baselines.

\textbf{Domain shift in NLP.} Cross-domain degradation is well-documented; adaptation and continued pretraining are common remedies \cite{blitzer2007biographies,gururangan2020don}.

\textbf{Dataset leakage and near-duplicates.} Deduplication improves evaluation validity \cite{lee2022dedup}.

\textbf{Adversarial text robustness.} TextAttack \cite{morris2020textattack} and DeepWordBug \cite{gao2018deepwordbug} reveal classifier brittleness.

\section{Threats to Validity}
\textbf{Domain coverage.} We evaluate SMS, email, and chat; other domains/languages may differ.\\
\textbf{DedupShift limitations.} SimHash may miss semantic paraphrases; sensitivity analysis explores threshold effects.\\
\textbf{Defense scope.} EAT and normalization are heuristics; multilingual/multimodal text may behave differently.

\section{Reproducibility}
All code, data preprocessing scripts, and trained models are released. One-command reproduction: \texttt{make paper\_repro}. This generates all tables, figures, and statistical analyses presented in this paper.

\bibliographystyle{plain}
\bibliography{refs}
\end{document}
