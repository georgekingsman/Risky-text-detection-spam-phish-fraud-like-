\documentclass[11pt]{article}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{geometry}
\geometry{margin=1in}
\graphicspath{{figs/}}

\title{DedupShift: Credible Cross-Domain Benchmarking for Risky Text Detection}
\author{}
\date{}

\begin{document}
\maketitle

\begin{abstract}
We present a reproducible benchmark for risky text detection (spam/phish/fraud-like) across SMS and email domains. We report strong in-domain baselines (F1 up to 0.99) but substantial cross-domain degradation, and show that even a neural anchor baseline (DistilBERT fine-tuning) does not eliminate domain shift. We introduce DedupShift, a deduplicated split protocol that reduces leakage from template-heavy corpora and changes robustness estimates. Our suite includes perturbation-based robustness, normalization defense ablation, TextAttack sanity checks, and domain-shift diagnostics.
\end{abstract}

\section{Introduction}
We study risky text detection under domain shift and adversarial perturbations. Our contributions are: (1) a two-domain benchmark with unified schema and reproducible pipeline; (2) DedupShift, a deduplicated split protocol to control leakage; (3) a robustness suite with defense ablations and a neural anchor baseline (DistilBERT-FT) for modern reference.

\section{Benchmark Setup}
We use SMS (UCI SMSSpamCollection) and SpamAssassin corpora with 80/10/10 stratified splits. DedupShift removes exact and near-duplicates (SimHash) before re-splitting to reduce leakage and template overlap.

\section{Baselines}
We report TF-IDF word LR, TF-IDF character SVM, MiniLM+LR, and DistilBERT-FT as a neural anchor baseline. We add two lightweight improvement baselines: (i) \textbf{AugTrain}, which applies training-time augmentation (obfuscation, paraphrase-like substitutions, and normalization) to spam samples; and (ii) \textbf{CORAL} domain alignment on MiniLM embeddings to reduce covariate shift. DistilBERT uses max length 128, batch 8, 2 epochs, seed 0.

\section{Results}
\input{tables/cross_domain_table_dedup.tex}
\input{tables/dedup_effect.tex}
\input{tables/domain_shift_stats.tex}
\input{tables/textattack_table.tex}

\begin{figure}[t]
\centering
\includegraphics[width=0.95\linewidth]{Pipeline.png}
\caption{Benchmark pipeline overview.}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.95\linewidth]{fig_robustness_delta_dedup.png}
\caption{Robustness deltas on deduplicated splits.}
\end{figure}

\section{Related Work}
\textbf{Spam/phish detection baselines.} Classic statistical filters and linear models with TF-IDF features remain strong baselines for spam detection \cite{guzella2009review,almeida2011sms}. Recent work adopts BERT-family models for text classification \cite{sanh2019distilbert}.

\textbf{Domain shift in NLP.} Cross-domain degradation is well-documented in sentiment and text classification; adaptation and continued pretraining are common remedies \cite{blitzer2007biographies,gururangan2020don}.

\textbf{Dataset leakage and near-duplicates.} Near-duplicate contamination can inflate evaluation scores; deduplication has been shown to improve validity in NLP benchmarks \cite{lee2022dedup}.

\textbf{Adversarial text and robustness.} Character-level and synonym-based attacks reveal brittleness of text classifiers; TextAttack provides standardized evaluation recipes \cite{gao2018deepwordbug,morris2020textattack,jin2020textfooler}.

\section{Threats to Validity and Limitations}
\textbf{Domain coverage.} We evaluate only SMS and email; broader domains and languages may exhibit different shift patterns.

\textbf{DedupShift approximation.} DedupShift removes exact and SimHash near-duplicates but may miss semantic paraphrases; dedup thresholds trade recall for precision.

\textbf{Defense scope.} Normalization and AugTrain are heuristic and may behave differently across formats or multilingual text.

\textbf{Adversarial evaluation.} TextAttack is run on subsets and is a diagnostic, not an exhaustive adversarial guarantee.

\section{Reproducibility and Artifacts}
We release processing scripts, fixed seeds, and Makefile targets for one-command reproduction (\texttt{make paper\_repro}). Key artifacts include cross-domain tables, robustness matrices, DedupShift reports, TextAttack summaries, and domain-shift diagnostics.

\bibliographystyle{plain}
\bibliography{refs}
\end{document}
